{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2490c6da-5bc7-4bd5-955c-411001eb1dd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './/DATASET//2017.arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 163\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28mprint\u001b[39m(row)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 125\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m datasetFile:\n\u001b[0;32m    123\u001b[0m         dataset_label \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 125\u001b[0m         attrs, data \u001b[38;5;241m=\u001b[39m \u001b[43mparse_arff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m    128\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(attrs)):\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mparse_arff\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m nom_mapping \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m      8\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './/DATASET//2017.arff'"
     ]
    }
   ],
   "source": [
    "def parse_arff(file_path):\n",
    "    data_started = False\n",
    "    attrs = []\n",
    "    data = []\n",
    "    nom_mapping = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line or line.startswith('%'):\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith('@relation'):\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith('@attribute'):\n",
    "                parts = line.split()\n",
    "                attr_name = parts[1].strip()\n",
    "\n",
    "                if '{' in line:\n",
    "                    values = line[line.index('{') + 1:line.index('}')].split(',')\n",
    "                    attrs.append((attr_name, 'nominal', values))\n",
    "                    attr_info = ((attr_name, 'nominal', values))\n",
    "\n",
    "                    attr_name, attr_type, attr_values = attr_info\n",
    "\n",
    "                    nom_mapping.append({value: index for index, value in enumerate(attr_values)})\n",
    "                else:\n",
    "                    attrs.append((attr_name, 'numeric', 0))\n",
    "\n",
    "            if line.lower().startswith('@data'):\n",
    "                data_started = True\n",
    "                continue\n",
    "\n",
    "            if data_started:\n",
    "                data_line = line.split(',')\n",
    "\n",
    "                data.append(line.split(','))\n",
    "\n",
    "    return attrs, data\n",
    "\n",
    "def standardize_data(features):\n",
    "    mean_X = []\n",
    "    std_X = []\n",
    "    std_Features = features\n",
    "\n",
    "    for index in range(len(features)):\n",
    "        mean_X.append(sum(features[index]) / len(features[index]))\n",
    "\n",
    "        std_X.append(((sum((x - mean_X[index]) ** 2 for x in features[index])) / (len(features[index]))) ** 0.5)\n",
    "\n",
    "    for indexStd in range(len(std_Features)):\n",
    "        std_Features[indexStd] = [((x - mean_X[indexStd]) / std_X[indexStd]) for x in std_Features[indexStd]]\n",
    "\n",
    "    return std_Features, mean_X, std_X\n",
    "\n",
    "def calculate_covariance_matrix(features):\n",
    "\n",
    "    n = len(features[0])\n",
    "    num_samples = len(features)\n",
    "    \n",
    "    mean_values = [sum(feature) / num_samples for feature in features]\n",
    "\n",
    "    cov_matrix = [[0] * num_samples for _ in range(num_samples)]\n",
    "\n",
    "    for x in range(num_samples):\n",
    "        for y in range(num_samples):\n",
    "            cov_matrix[x][y] = sum((features[x][i] - mean_values[x]) * (features[y][i] - mean_values[y]) for i in range(n)) / (n - 1)\n",
    "    \n",
    "    return cov_matrix\n",
    "\n",
    "def dot_prod(vec1, vec2):\n",
    "    return sum(x * y for x, y in zip(vec1, vec2))\n",
    "\n",
    "def scalar_mult(scalar, vec):\n",
    "    return [scalar * x for x in vec]\n",
    "\n",
    "def subtract_vecs(vec1, vec2):\n",
    "    return [x - y for x, y in zip(vec1, vec2)]\n",
    "\n",
    "def transpose(matrix):\n",
    "    return [[row[i] for row in matrix] for i in range(len(matrix[0]))]\n",
    "\n",
    "def mat_mult(mat1, mat2):\n",
    "    return [[dot_prod(row, col) for col in transpose(mat2)] for row in mat1]\n",
    "\n",
    "def svd(data):\n",
    "    mean_vec = [sum(feature) / len(data) for feature in transpose(data)]\n",
    "    centered_data = [subtract_vecs(row, mean_vec) for row in data]\n",
    "\n",
    "    cov_matrix = mat_mult(transpose(centered_data), centered_data)\n",
    "\n",
    "    singular_vec = [1.0] * len(cov_matrix[0])\n",
    "    for _ in range(50):\n",
    "        singular_vec = mat_mult([singular_vec], cov_matrix)[0]\n",
    "        magnitude = sum(x ** 2 for x in singular_vec) ** 0.5\n",
    "        singular_vec = scalar_mult(1.0 / magnitude, singular_vec)\n",
    "\n",
    "    u_mat = [singular_vec]\n",
    "    v_mat = [singular_vec]\n",
    "\n",
    "    singular_val = dot_prod(centered_data[0], singular_vec)\n",
    "    s_mat = [[singular_val if i == j else 0.0 for j in range(len(u_mat))] for i in range(len(v_mat))]\n",
    "\n",
    "    return u_mat, s_mat, transpose(v_mat)\n",
    "\n",
    "def perform_pca(data, num_components):\n",
    "    mean_vec = [sum(feature) / len(data) for feature in transpose(data)]\n",
    "    centered_data = [subtract_vecs(row, mean_vec) for row in data]\n",
    "\n",
    "    cov_matrix = mat_mult(transpose(centered_data), centered_data)\n",
    "    u_mat, _, v_t = svd(cov_matrix)\n",
    "\n",
    "    principal_comp = [row[:num_components] for row in transpose(v_t)]\n",
    "    projected_data = mat_mult(centered_data, principal_comp)\n",
    "\n",
    "    return projected_data\n",
    "\n",
    "def main():\n",
    "    datasetFile = ['.//DATASET//2017.arff','.//DATASET//2018.arff','.//DATASET/2019.arff','.//DATASET//2020.arff','./DATASET/2021 Q1.arff']\n",
    "    \n",
    "    for file_path in datasetFile:\n",
    "            dataset_label = file_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "            attrs, data = parse_arff(file_path)\n",
    "    \n",
    "            for row in data:\n",
    "                for i in range(len(attrs)):\n",
    "                    attr_name, attr_type, attr_values = attrs[i]\n",
    "                    if attr_type == 'nominal':\n",
    "                        nom_mapping = {value: index for index, value in enumerate(attr_values)}\n",
    "                        row[i] = nom_mapping.get(row[i])\n",
    "                    elif attr_type == 'numeric':\n",
    "                        try:\n",
    "                            row[i] = float(row[i])\n",
    "                        except Exception as e:\n",
    "                            row[i] = -1\n",
    "    \n",
    "    data_as_list = [list(map(float, row)) for row in data]\n",
    "    \n",
    "    num_comp_pca = 3\n",
    "    projected_data_pca = perform_pca(data_as_list, num_comp_pca)\n",
    "    \n",
    "    print(\"\\nProjected Data (PCA):\")\n",
    "    for row in projected_data_pca:\n",
    "                print(row)\n",
    "    \n",
    "    u_svd, s_svd, v_t_svd = svd(data_as_list)\n",
    "    \n",
    "    print(\"\\nMatrix U (SVD):\")\n",
    "    for row in u_svd:\n",
    "        print(row)\n",
    "    \n",
    "    print(\"\\nMatrix S (SVD):\")\n",
    "    for row in s_svd:\n",
    "        print(row)\n",
    "    \n",
    "    print(\"\\nMatrix V^T (SVD):\")\n",
    "    for row in v_t_svd:\n",
    "        print(row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "720e6b46-6e51-42fb-b272-eea19e02bb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Num   | Country          | X1    | X2    | X3    | X4    | X5    |\n",
      "| 10    | Hungary          | m     | m     | m     | m     | m     |\n",
      "| 22    | Poland           | -0.03 | 0.58  | -0.03 | 0.85  | 0.02  |\n",
      "| 27    | Hungary          | m     | m     | m     | m     | m     |\n",
      "| 73    | Poland           | 0.01  | 0.71  | 0.08  | 1.13  | 0.11  |\n",
      "| 74    | Poland           | -0.13 | 1.1   | -0.43 | 0.27  | -0.05 |\n",
      "| 100   | Poland           | 0     | 0     | 0     | 0     | 0     |\n",
      "| 139   | Poland           | 0.07  | 0.63  | 0.18  | 1.32  | 0.08  |\n",
      "| 142   | 'Czech Republic' | 0     | 0.19  | 0.13  | 2.88  | 0.44  |\n",
      "| 175   | Poland           | 0.06  | 0.52  | 0.05  | 1.14  | 0.05  |\n",
      "| 217   | Poland           | 0     | 0     | 0     | 0     | 0     |\n",
      "| 257   | Hungary          | m     | m     | m     | m     | m     |\n",
      "| 270   | Poland           | 0.02  | 0.65  | 0.03  | 1.06  | 0.02  |\n",
      "| 276   | Poland           | 0.23  | 0.52  | 0.32  | 1.79  | 0.23  |\n",
      "| 290   | Poland           | 0.22  | 0.3   | 0.41  | 2.98  | 0.22  |\n",
      "| 366   | Poland           | m     | m     | m     | m     | m     |\n",
      "| 405   | Poland           | 0     | 0.26  | 0.27  | 2.04  | 0     |\n",
      "| 415   | Poland           | -0.83 | 0.19  | -0.05 | 0.15  | 0     |\n",
      "| 12    | Poland           | 0.03  | 0.73  | 0.22  | 1.32  | 0.09  |\n",
      "| 19    | Poland           | 0     | 0     | 0     | 0     | 0     |\n",
      "| 21    | Poland           | 0.04  | 0.66  | 0.21  | 1.36  | 0.05  |\n"
     ]
    }
   ],
   "source": [
    "def read_arff(file_path):\n",
    "    attributes = []\n",
    "    data = []\n",
    "    data_start = False\n",
    "    count = 0\n",
    "    with open(file_path, 'r') as file:\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line or line.startswith('%'):\n",
    "                continue\n",
    "            if data_start:\n",
    "                data.append(line.split(','))\n",
    "            elif line.lower().startswith('@attribute'):\n",
    "                attributes.append(line.split()[1])\n",
    "            elif line.lower().startswith('@data'):\n",
    "                data_start = True\n",
    "\n",
    "    return attributes, data\n",
    "def truncate_string(input_str, max_length):\n",
    "    if len(input_str) > max_length:\n",
    "        return input_str[:max_length] + '...'\n",
    "    else:\n",
    "        return input_str\n",
    "print(\"| {:<5} | {:<16} | {:<5} | {:<5} | {:<5} | {:<5} | {:<5} |\".format(*attrib[:7]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in data[:20]:\n",
    "    print(\"| {:<5} | {:<16} | {:<5} | {:<5} | {:<5} | {:<5} | {:<5} |\".format(*row[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d274af2-425e-4a89-b819-1df4d3c2b514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9830e8-38f9-42a3-bf64-8f6865ab147b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
